<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Training autoregressive LMs to natively synthesize programs with diff sequences improves the trade-off between generation quality and inference-time compute.">
  <meta name="keywords" content="inference-time scaling laws, code synthesis, code generation, language model, language models, LLMs, edit sequences, diff sequences, lintseq">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LintSeq: Synthetic Data for Diff-by-Diff Code Synthesis with Language Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-3MZZ3FXP27"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-3MZZ3FXP27');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://upiterbarg.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://arxiv.org/abs/2305.19240">
            NetHack is Hard to Hack
          </a>
          <a class="navbar-item" href="https://arxiv.org/abs/2312.07540">
            diff History for Neural Language Agents
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Training Language Models on Synthetic Edit Sequences Improves Code Synthesis</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://upiterbarg.github.io">Ulyana Piterbarg</a>,</span>
            <span class="author-block">
              <a href="https://www.lerrelpinto.com">Lerrel Pinto</a>,</span>
            <span class="author-block">
              <a href="https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php">Rob Fergus</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">New York University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2410.02749"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2410.02749"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/upiterbarg/lintseq"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- TinyCodeLMs. -->
              <span class="link-block">
                <a href="https://huggingface.co/collections/upiter/tinycodelm-6709636f4aba6241d547334f"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-file"></i>
                  </span>
                  <span>TinyCodeLMs</span>
                  </a>
              </span>
              <!-- PyLintSeq. -->
              <span class="link-block">
                <a href="https://pypi.org/project/pylintseq/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-wrench"></i>
                  </span>
                  <span>Install PyLintSeq</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser.png"
             class="interpolation-image"
             alt="A visualization of LintSeq."
             width=100%
             />
      <h2 class="subtitle has-text-justified">
         <b><span class="diff"> Training autoregressive LMs to synthesize code edit-by-edit improves the slope of test-time scaling laws on benchmarks like HumanEval, MBPP, and CodeContests</span></b>. Our approach introduces an algorithm, LintSeq, that uses code linters to generate synthetic edit data for code synthesis at scale. Edits sampled with this algorithm reflect the semantics & syntax of their programming language, modeling human-like abstractions. We show that pre-processing SFT data with LintSeq results in models that produce high-quality & more diverse programs when sampled from at test-time, suggesting that LMs benefit from the addition of human-like abstractions to training data.
      </h2>
    </div>
  </div>
</section>


<br>
<br>




<section class="section" style="background-color:#f7f7f7">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          
          Software engineers mainly write code by editing existing programs. In contrast, language models (LMs) autoregressively synthesize programs in a single pass. One explanation for this is the scarcity of sequential edit data. While high-quality instruction data for code synthesis is scarce, edit data for synthesis is even scarcer. 
          <br>
          <br>
          To fill this gap, we develop a synthetic data generation algorithm called LintSeq. This algorithm refactors programs into sequences of synthetic edits by using a linter to procedurally sample across interdependent lines of source code. <b>Synthetic edits sampled with LintSeq reflect the syntax and semantics of their programming language.</b>
          <br>
          <br>
           To test the algorithm, we use it to refactor a dataset of instruction + program pairs into instruction + program-diff-sequence tuples. Then, we fine-tune a series of smaller LMs ranging from 2.6B to 14B parameters on both the re-factored and original versions of this dataset. We perform comprehensive evaluations comparing edit sequence code LMs against baselines on HumanEval, MBPP(+), CodeContests, DS-1000, and BigCodeBench. <b>We show that models fine-tuned to iteratively synthesize code match or outperform baselines on pass@1, and exhibit better scaling across higher pass@k as a function of total test-time FLOPs.</b> Finally, we also pretrain our own tiny LMs for code understanding. We show that fine-tuning these models to synthesize code edit-by-edit results in strong performance on HumanEval and MBPP(+) compared to existing code language models of similar scale such as AlphaCode and Codex.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<br>
<br>


<!-- Section 1 -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-multiline">
      <div class="column is-12">
        <h2 class="title">1. LintSeq: Code Generation as a Sequential Edit Problem</h2>
        <p>
           At each iteration, the LintSeq algorithm samples an edit chunk from a program by: randomly selecting a line of code to delete; identifying the minimal set of lines that are dependent on this line with a code linter; and finally, removing the line and its dependents. These steps are repeated until all lines of code have been removed. LintSeq then processes the reversed sequence of program states with Unix-diff to express it as a sequence of edits.
           <br>
           <br>
           Intuitively, LintSeq decomposes source code across semantically/syntactically interdependent edit chunks. A synthetic Python edit output by LintSeq might contain: the full body of a "for" loop, a declaration of a variable (e.g. "a = 10") and all subsequent lines of code referencing this variable, or an entire function definition. By design, each LintSeq edit also satisfies a "linter-correctness" invariant, i.e. applying it to previously written code does not introduce new linter errors.
        </p>
        <div class="hero-body"  style="text-align: center;" >
        <img src="./static/images/lintseq_viz.png"
             class="interpolation-image"
             alt="A visualization of LintSeq."
             width=100%
             />
          <br>
          <br>
      </div>
      </div>
    </div>
  </div>
 
</section>

<!-- Section 2 -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-multiline">
      <div class="column is-12">
        <h2 class="title">2. Sequential Code Generation improves the Slope of Test-Time Scaling Laws for Repeated Sampling</h2>
        <p>
          By adding edits that reflect programming language abstractions to instruction data with LintSeq, we train language models to synthesize programs one ("linted") edit at a time. This results in <b>substantial improvements to the overall diversity of model-generated code</b>, compared to training on a dataset of equivalent "single-shot" instruction data for code synthesis. The improved diversity of sampled programs means that pass@k performance increases faster as a function of test-time FLOPs, allowing for a better trade-off between the two. We demonstrate this effect on four different language models. 
          <br>
          <br>
          In the figure below, we report the best performance of models SFT-ed on edit sequence pre-processed vs standard instruction data after sweeping over sampling temperature, top-p, and min-p. We then plot benchmark score (pass@k) as a function of the total cost of repeated sampling from each model in FLOPs. Shading shows standard error in linear fit.

          <div class="hero-body"  style="text-align: center;" >
          <img src="./static/images/test_time_v2.png"
             class="interpolation-image"
             alt="LMs from the Gemma 2, Phi-3, and Llama 3 families exhibit better inference-time scaling laws during repeated sampling when SFT-ed on program diff sequences rather than on standard program data."
             width=100%
             />
          <br>
          <br>
      </div>
      </div>
    </div>
  </div>
  
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{piterbarg2024editseq,
      title={Training Language Models on Synthetic Edit Sequences Improves Code Synthesis}, 
      author={Ulyana Piterbarg and Lerrel Pinto and Rob Fergus},
      year={2024},
      eprint={2410.02749},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
      }
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a> and is based on the Nerfies website <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> from Park et al.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
